# Docker Compose V2+ - no version required

networks:
  ai_platform_network:
    driver: bridge
  pl-ai-network:
    driver: bridge

volumes:
  analysis_db_data:
  analysis_results_data:
  chatbot_db_data:
  classifier_db_data:
  image_generator_db_data:
  image_generator_media:
  models_storage_data:
  postgres_data:
  rabbitmq_data:
  resource_db_data:
  resource_media_data:
  rag_db_data:
  rag_uploads_data:
  rag_embeddings_data:
  user_db_data:
  learning_db_data:

secrets:
  anthropic_api_key_secret:
    file: ./.secrets/anthropic_api_key.txt
  gemini_api_key_secret:
    file: ./.secrets/gemini_api_key.txt
  openai_api_key_secret:
    file: ./.secrets/openai_api_key.txt
  stability_api_key_secret:
    file: ./.secrets/stability_api_key.txt

services:
  # =============================================================================
  # DATABASE SERVICES
  # =============================================================================
  
  auth_db:
    image: postgres:15-alpine
    container_name: pl-ai-auth-db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${AUTH_DB_USER:-plai_user}
      POSTGRES_PASSWORD: ${AUTH_DB_PASSWORD:-plai_password}
      POSTGRES_DB: ${AUTH_DB_NAME:-plai_db}
    expose: ["5432"]
    ports: ["5433:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-plai_user} -d $${POSTGRES_DB:-plai_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  user_db:
    image: postgres:15-alpine
    container_name: pl-ai-user-db
    volumes:
      - user_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${USER_DB_USER:-user_user}
      POSTGRES_PASSWORD: ${USER_DB_PASSWORD:-user_password}
      POSTGRES_DB: ${USER_DB_NAME:-user_db}
    expose: ["5432"]
    ports: ["5434:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-user_user} -d $${POSTGRES_DB:-user_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  chatbot_db:
    image: postgres:15-alpine
    container_name: pl-ai-chatbot-db
    volumes:
      - chatbot_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${CHATBOT_DB_USER:-chatbot_user}
      POSTGRES_PASSWORD: ${CHATBOT_DB_PASSWORD:-chatbot_pass}
      POSTGRES_DB: ${CHATBOT_DB_NAME:-chatbot_db}
    expose: ["5432"]
    ports: ["5435:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-chatbot_user} -d $${POSTGRES_DB:-chatbot_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  image_generator_db:
    image: postgres:15-alpine
    container_name: pl-ai-image-generator-db
    volumes:
      - image_generator_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${IMAGE_GEN_DB_USER:-imagegen_user}
      POSTGRES_PASSWORD: ${IMAGE_GEN_DB_PASSWORD:-imagegen_password}
      POSTGRES_DB: ${IMAGE_GEN_DB_NAME:-imagegen_db}
    expose: ["5432"]
    ports: ["5436:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-imagegen_user} -d $${POSTGRES_DB:-imagegen_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  resource_db:
    image: postgres:15-alpine
    container_name: pl-ai-resource-db
    volumes:
      - resource_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${RESOURCE_DB_USER:-resource_user}
      POSTGRES_PASSWORD: ${RESOURCE_DB_PASSWORD:-resource_password}
      POSTGRES_DB: ${RESOURCE_DB_NAME:-resource_db}
    expose: ["5432"]
    ports: ["5437:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-resource_user} -d $${POSTGRES_DB:-resource_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  classifier_db:
    image: postgres:15-alpine
    container_name: pl-ai-classifier-db
    volumes:
      - classifier_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${CLASSIFIER_DB_USER:-classifier_user}
      POSTGRES_PASSWORD: ${CLASSIFIER_DB_PASSWORD:-classifier_password}
      POSTGRES_DB: ${CLASSIFIER_DB_NAME:-classifier_db}
    expose: ["5432"]
    ports: ["5438:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-classifier_user} -d $${POSTGRES_DB:-classifier_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  analysis_db:
    image: postgres:15-alpine
    container_name: pl-ai-analysis-db
    volumes:
      - analysis_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${ANALYSIS_DB_USER:-analysis_user}
      POSTGRES_PASSWORD: ${ANALYSIS_DB_PASSWORD:-analysis_password}
      POSTGRES_DB: ${ANALYSIS_DB_NAME:-analysis_db}
    expose: ["5432"]
    ports: ["5439:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-analysis_user} -d $${POSTGRES_DB:-analysis_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  rag_db:
    image: postgres:15-alpine
    container_name: pl-ai-rag-db
    volumes:
      - rag_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${RAG_DB_USER:-rag_user}
      POSTGRES_PASSWORD: ${RAG_DB_PASSWORD:-rag_password}
      POSTGRES_DB: ${RAG_DB_NAME:-rag_db}
    expose: ["5432"]
    ports: ["5440:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-rag_user} -d $${POSTGRES_DB:-rag_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  learning_db:
    image: postgres:15-alpine
    container_name: pl-ai-learning-db
    volumes:
      - learning_db_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${LEARNING_DB_USER:-learning_user}
      POSTGRES_PASSWORD: ${LEARNING_DB_PASSWORD:-learning_password}
      POSTGRES_DB: ${LEARNING_DB_NAME:-learning_db}
    expose: ["5432"]
    ports: ["5441:5432"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER:-learning_user} -d $${POSTGRES_DB:-learning_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # =============================================================================
  # MESSAGE BROKER
  # =============================================================================
  
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: pl-ai-rabbitmq
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
    ports: ["15672:15672"]
    expose: ["5672"]
    networks: [pl-ai-network]
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_running", "-q"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # =============================================================================
  # BACKEND SERVICES (API)
  # =============================================================================
  
  auth_service:
    build:
      context: ./backend/auth_service
    container_name: pl-ai-auth-service
    env_file: [./backend/auth_service/.env]
    volumes:
      - ./backend/auth_service:/app
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      auth_db: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  user_service:
    build:
      context: ./backend/user_service
    container_name: pl-ai-user-service
    env_file: [./backend/user_service/.env]
    volumes:
      - ./backend/user_service:/app
      - ./backend/user_service/mediafiles:/mediafiles
    secrets:
      - openai_api_key_secret
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      user_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  chatbot_service:
    build:
      context: ./backend/chatbot_service
    container_name: pl-ai-chatbot-service
    environment:
      DB_NAME: ${CHATBOT_DB_NAME:-chatbot_db}
      DB_USER: ${CHATBOT_DB_USER:-chatbot_user}
      DB_PASSWORD: ${CHATBOT_DB_PASSWORD:-chatbot_pass}
      DB_HOST: chatbot_db
      DB_PORT: 5432
      OPENAI_API_KEY_FILE: /run/secrets/openai_api_key_secret
      GEMINI_API_KEY_FILE: /run/secrets/gemini_api_key_secret
      ANTHROPIC_API_KEY_FILE: /run/secrets/anthropic_api_key_secret
    volumes:
      - ./backend/chatbot_service:/app
    secrets:
      - openai_api_key_secret
      - gemini_api_key_secret
      - anthropic_api_key_secret
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      chatbot_db: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  image_generator_service:
    build:
      context: ./backend/image_generator_service
    container_name: pl-ai-image-generator-service
    env_file: [./backend/image_generator_service/.env]
    volumes:
      - ./backend/image_generator_service:/app
      - image_generator_media:/app/mediafiles
    secrets:
      - openai_api_key_secret
      - stability_api_key_secret
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      image_generator_db: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s
    restart: unless-stopped

  resource_manager_service:
    build:
      context: ./backend/resource_manager_service
    container_name: pl-ai-resource-manager-service
    env_file: [./backend/resource_manager_service/.env]
    environment: [SERVICE_PROCESS_TYPE=web]
    volumes:
      - ./backend/resource_manager_service:/app
      - ./backend/resource_manager_service/mediafiles:/mediafiles
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      resource_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 45s
    restart: unless-stopped

  image_classifier_service:
    build:
      context: ./backend/image_classifier_service
    container_name: pl-ai-classifier-service
    env_file: [./backend/image_classifier_service/.env]
    environment: [SERVICE_PROCESS_TYPE=web]
    volumes:
      - ./backend/image_classifier_service:/app
      - models_storage_data:/app/models_storage
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      classifier_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  data_analysis_service:
    build:
      context: ./backend/data_analysis_service
      dockerfile: Dockerfile
    container_name: pl-ai-data-analysis-service
    env_file: [./backend/data_analysis_service/.env]
    environment: [SERVICE_PROCESS_TYPE=web]
    volumes:
      - ./backend/data_analysis_service:/app
      - analysis_results_data:/app/analysis_results_storage
    secrets:
      - openai_api_key_secret
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      analysis_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
      resource_manager_service: { condition: service_started }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  rag_service:
    build:
      context: ./backend/rag_service
      dockerfile: Dockerfile
    container_name: pl-ai-rag-service
    env_file: [./backend/rag_service/.env]
    environment: [SERVICE_PROCESS_TYPE=web]
    volumes:
      - ./backend/rag_service:/app
      - rag_uploads_data:/app/rag_uploads
      - rag_embeddings_data:/app/rag_embeddings
    secrets:
      - openai_api_key_secret
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      rag_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  learning_service:
    build:
      context: ./backend/learning_service
    container_name: pl-ai-learning-service
    env_file: [./backend/learning_service/.env]
    volumes:
      - ./backend/learning_service:/app
      - ./backend/learning_service/mediafiles:/mediafiles
      - ./backend/learning_service/logs:/app/logs
    secrets:
      - openai_api_key_secret
    expose: ["8000"]
    networks: [pl-ai-network]
    depends_on:
      learning_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8000/admin/login/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: unless-stopped

  # =============================================================================
  # WORKER SERVICES (Background Tasks)  
  # =============================================================================
  
  rag_worker:
    build:
      context: ./backend/rag_service
      dockerfile: Dockerfile
    container_name: pl-ai-rag-worker
    env_file: [./backend/rag_service/.env]
    environment: [SERVICE_PROCESS_TYPE=worker]
    volumes:
      - ./backend/rag_service:/app
      - rag_uploads_data:/app/rag_uploads
      - rag_embeddings_data:/app/rag_embeddings
    secrets:
      - openai_api_key_secret
    networks: [pl-ai-network]
    depends_on:
      rag_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    restart: unless-stopped

  data_analysis_worker:
    build:
      context: ./backend/data_analysis_service
    container_name: pl-ai-data-analysis-worker
    entrypoint: ""
    command: ["celery", "-A", "service_config", "worker", "--loglevel=INFO", "-Q", "analysis_tasks", "-c", "1"]
    env_file: [./backend/data_analysis_service/.env]
    volumes:
      - ./backend/data_analysis_service:/app
      - analysis_results_data:/app/analysis_results_storage
    secrets:
      - openai_api_key_secret
    networks: [pl-ai-network]
    depends_on:
      analysis_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
      resource_manager_service: { condition: service_started }
    restart: unless-stopped

  image_classifier_worker:
    build:
      context: ./backend/image_classifier_service
    container_name: pl-ai-classifier-worker
    entrypoint: ""
    command: ["celery", "-A", "service_config", "worker", "--loglevel=INFO", "-Q", "classifier_tasks", "-c", "1"]
    env_file: [./backend/image_classifier_service/.env]
    volumes:
      - ./backend/image_classifier_service:/app
      - models_storage_data:/app/models_storage
    networks: [pl-ai-network]
    depends_on:
      classifier_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    restart: unless-stopped

  resource_manager_worker:
    build:
      context: ./backend/resource_manager_service
    container_name: pl-ai-resource-manager-worker
    entrypoint: ""
    command: ["celery", "-A", "service_config", "worker", "--loglevel=INFO", "-Q", "resource_tasks"]
    env_file: [./backend/resource_manager_service/.env]
    volumes:
      - ./backend/resource_manager_service:/app
      - ./backend/resource_manager_service/mediafiles:/mediafiles
    networks: [pl-ai-network]
    depends_on:
      resource_db: { condition: service_healthy }
      rabbitmq: { condition: service_healthy }
    restart: unless-stopped

  # =============================================================================
  # FRONTEND SERVICE
  # =============================================================================
  
  frontend:
    build:
      context: ./frontend
    container_name: pl-ai-frontend
    expose: ["3000"]
    networks: [pl-ai-network]
    restart: unless-stopped

  # =============================================================================
  # API GATEWAY / REVERSE PROXY
  # =============================================================================
  
  nginx:
    build:
      context: ./nginx
    container_name: pl-ai-nginx
    ports: ["8080:80"]
    networks:
      - pl-ai-network
      - ai_platform_network
    volumes:
      - analysis_results_data:/media_analysis_results:ro
      - image_generator_media:/media_images:ro
      - ./backend/resource_manager_service/mediafiles:/media_resources
      - ./backend/user_service/mediafiles:/media_users:ro
      - rag_uploads_data:/media_rag_uploads:ro
    depends_on:
      auth_service: { condition: service_healthy }
      user_service: { condition: service_healthy }
      image_generator_service: { condition: service_healthy }
      resource_manager_service: { condition: service_healthy }
      image_classifier_service: { condition: service_started }
      data_analysis_service: { condition: service_healthy }
      rag_service: { condition: service_healthy }
      learning_service: { condition: service_healthy }
      frontend: { condition: service_started }
    restart: unless-stopped